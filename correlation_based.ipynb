{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNJH7l48HkQfVfohmF7396r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aashikrasool/Coefficient-Based-Data-Generator/blob/main/correlation_based.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ***Data preprocess***"
      ],
      "metadata": {
        "id": "FoMisRdR3Z6w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B10ZHUPs9pxS"
      },
      "outputs": [],
      "source": [
        "#this process is for mount data from colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "crop_data=pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Crop_recommendation.csv\")"
      ],
      "metadata": {
        "id": "_NCgzUzw9srH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crop_data.head()"
      ],
      "metadata": {
        "id": "BI20tjTI9zkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crop_data['label']"
      ],
      "metadata": {
        "id": "iudK-P-yasAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an empty dictionary to store data for each crop type\n",
        "crop_dict = {}"
      ],
      "metadata": {
        "id": "vkPU1Hxaau0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Create global variables for each crop type\n",
        "for label in crop_data['label'].unique():\n",
        "    globals()[f\"{label}_data\"] = crop_data[crop_data['label'] == label]\n",
        "\n",
        "# Print the names of these variables\n",
        "print(\"Created variable names:\")\n",
        "for label in crop_data['label'].unique():\n",
        "    crop_var_name = f\"{label}_data\"\n",
        "    if crop_var_name in globals():\n",
        "        print(crop_var_name)\n"
      ],
      "metadata": {
        "id": "VsFiw6tmba39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#producing class wise\n",
        "rice_correlation = rice.corr()"
      ],
      "metadata": {
        "id": "E-qvg_ti-bFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming you have numeric columns in the 'rice' DataFrame\n",
        "rice_correlation =jute_data.corr()\n",
        "\n",
        "# Set up the matplotlib figure\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "# Create a heatmap using seaborn\n",
        "sns.heatmap(rice_correlation, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "\n",
        "# Display the plot\n",
        "plt.title('Correlation Matrix - Rice Data')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ajn9YLfv-3It"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "real_data = pomegranate_data\n",
        "origianl_df=pomegranate_data\n",
        "# Extract correlation coefficients from real data\n",
        "correlation_matrix = real_data.corr()\n",
        "correlation_coefficient = correlation_matrix.iloc[0, 1]"
      ],
      "metadata": {
        "id": "5GcOW_kk_BpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_data.head()"
      ],
      "metadata": {
        "id": "vq2AdPico13W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correlation_matrix"
      ],
      "metadata": {
        "id": "rXKIa9wyFZ54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "real_data['label'] = label_encoder.fit_transform(real_data['label'])"
      ],
      "metadata": {
        "id": "SX-JfQ8dpAXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_data['label']"
      ],
      "metadata": {
        "id": "2oyXZ1mypElH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build GAN\n"
      ],
      "metadata": {
        "id": "lbYAP-Sj35ST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Generate synthetic data with correlation\n",
        "def generate_data(num_samples, correlation_coefficient):\n",
        "    np.random.seed(42)\n",
        "    data = np.random.rand(num_samples, 8)\n",
        "    correlated_feature = correlation_coefficient * data[:, 0] + 0.2 * np.random.rand(num_samples)\n",
        "    data[:, 1] = correlated_feature\n",
        "    return data\n",
        "\n",
        "# Define a custom self-attention layer\n",
        "class SelfAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(SelfAttention, self).__init__()\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.Wq = self.add_weight(shape=(input_shape[-1], input_shape[-1]), initializer='random_normal', trainable=True)\n",
        "        self.Wk = self.add_weight(shape=(input_shape[-1], input_shape[-1]), initializer='random_normal', trainable=True)\n",
        "        self.Wv = self.add_weight(shape=(input_shape[-1], input_shape[-1]), initializer='random_normal', trainable=True)\n",
        "\n",
        "    def call(self, x):\n",
        "        Q = tf.matmul(x, self.Wq)\n",
        "        K = tf.matmul(x, self.Wk)\n",
        "        V = tf.matmul(x, self.Wv)\n",
        "\n",
        "        attention_weights = tf.nn.softmax(tf.matmul(Q, K, transpose_b=True) / tf.math.sqrt(tf.cast(tf.shape(K)[-1], tf.float32)))\n",
        "        output = tf.matmul(attention_weights, V)\n",
        "\n",
        "        return output\n",
        "\n",
        "# Define the generator model\n",
        "def build_generator(latent_dim, output_dim):\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # Input layer\n",
        "    model.add(layers.Dense(32, input_dim=latent_dim, activation='relu'))\n",
        "\n",
        "    # Add self-attention layer\n",
        "    model.add(SelfAttention())\n",
        "\n",
        "    # Additional hidden layers\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dense(128, activation='relu'))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(layers.Dense(output_dim, activation='linear'))  # Change output_dim to 7\n",
        "\n",
        "    return model\n",
        "# Define the discriminator model\n",
        "def build_discriminator(input_dim):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Dense(32, input_dim=input_dim, activation='relu'))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Build and compile the GAN model with correlation loss\n",
        "def build_gan(generator, discriminator, correlation_coefficient):\n",
        "    discriminator.trainable = False\n",
        "    gan_model = models.Sequential()\n",
        "    gan_model.add(generator)\n",
        "    gan_model.add(discriminator)\n",
        "\n",
        "    # Add correlation loss to the generator's loss function\n",
        "    gan_model.compile(loss=['binary_crossentropy', 'mean_squared_error'], optimizer='adam')\n",
        "    return gan_model\n",
        "\n",
        "def train_gan(generator, discriminator, gan_model, data, epochs, batch_size, latent_dim, correlation_coefficient):\n",
        "    for epoch in range(epochs):\n",
        "        # Train discriminator\n",
        "        idx = np.random.randint(0, data.shape[0], batch_size)\n",
        "        real_data = data[idx]\n",
        "        fake_data = generator.predict(np.random.randn(batch_size, latent_dim))\n",
        "        labels_real = np.ones((batch_size, 1))\n",
        "        labels_fake = np.zeros((batch_size, 1))\n",
        "        d_loss_real = discriminator.train_on_batch(real_data, labels_real)\n",
        "        d_loss_fake = discriminator.train_on_batch(fake_data, labels_fake)\n",
        "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "        # Train generator with correlation loss\n",
        "        noise = np.random.randn(batch_size, latent_dim)\n",
        "        labels_gan = np.ones((batch_size, 1))\n",
        "        correlation_target = correlation_coefficient * noise[:, 0]  # Target correlation for the generated data\n",
        "        g_loss = gan_model.train_on_batch(noise, [labels_gan, correlation_target])\n",
        "\n",
        "        # Print progress\n",
        "        if epoch % 1000 == 0:\n",
        "            print(f\"Epoch {epoch}, D Loss: {d_loss}, G Loss: {g_loss}\")\n",
        "\n",
        "# Set parameters\n",
        "num_samples = len(real_data)\n",
        "latent_dim = 10\n",
        "data_shape = 8  # Change this based on the number of features in your data\n",
        "epochs = 1000 # Increase the number of epochs for better training\n",
        "batch_size = 64\n",
        "\n",
        "# Split data into train and test sets\n",
        "train_data, test_data = train_test_split(real_data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Extract correlation coefficients from real training data\n",
        "train_correlation_matrix = train_data.corr()\n",
        "train_correlation_coefficient = train_correlation_matrix.iloc[0, 1]\n",
        "# Print the data type of train_data.values\n",
        "print(train_data.values.dtype)\n",
        "# Generate correlated data using only the training data\n",
        "num_samples_train = len(train_data)\n",
        "synthetic_data_train = generate_data(num_samples_train, train_correlation_coefficient)\n",
        "\n",
        "# Denormalize synthetic data if necessary\n",
        "\n",
        "# Display synthetic data for training\n",
        "synthetic_df_train = pd.DataFrame(synthetic_data_train, columns=[f'Feature_{i+1}' for i in range(data_shape)])\n",
        "print(\"Synthetic Data (Training):\")\n",
        "print(synthetic_df_train.head())\n",
        "\n",
        "# Build and compile models\n",
        "generator = build_generator(latent_dim, data_shape)\n",
        "discriminator = build_discriminator(data_shape)\n",
        "gan_model = build_gan(generator, discriminator, train_correlation_coefficient)\n",
        "\n",
        "# Train the GAN on the training data\n",
        "train_gan(generator, discriminator, gan_model, train_data.values, epochs, batch_size, latent_dim, train_correlation_coefficient)\n",
        "\n",
        "# Evaluate correlation between generated and real data after training\n",
        "num_samples_test = len(test_data)\n",
        "synthetic_data_test = generator.predict(np.random.randn(num_samples_test, latent_dim))\n",
        "synthetic_df_test = pd.DataFrame(synthetic_data_test, columns=[f'Feature_{i+1}' for i in range(data_shape)])\n",
        "\n",
        "correlation_matrix_synthetic = synthetic_df_test.corr()\n",
        "correlation_coefficient_synthetic = correlation_matrix_synthetic.iloc[0, 1]\n",
        "\n",
        "print(f\"Correlation Coefficient between Real and Synthetic Data: {correlation_coefficient_synthetic}\")\n",
        "print(type(train_data.values))\n",
        "# # Display synthetic data for training\n",
        "# synthetic_df_train = pd.DataFrame(synthetic_data_train, columns=[f'Feature_{i+1}' for i in range(data_shape)])\n",
        "# print(\"Synthetic Data (Training):\")\n",
        "# print(synthetic_df_train.head())\n",
        "\n",
        "# Extract column names from the original data\n",
        "original_column_names = real_data.columns\n",
        "\n",
        "# Display synthetic data for training\n",
        "synthetic_df_train = pd.DataFrame(synthetic_data_train, columns=original_column_names)\n",
        "# synthetic_df_train = synthetic_df_train *100\n",
        "print(\"Synthetic Data (Training):\")\n",
        "print(synthetic_df_train.head())\n",
        "\n",
        "# # Scale synthetic data to match the value range of the original data\n",
        "# for column in original_column_names:\n",
        "#     min_val = real_data[column].min()\n",
        "#     max_val = real_data[column].max()\n",
        "#     synthetic_df_train[column] = synthetic_df_train[column] * (max_val - min_val) + min_val\n",
        "\n",
        "# Save synthetic data to CSV with the same column names and value range as the original data\n",
        "synthetic_df_train.to_csv('/content/drive/MyDrive/Colab Notebooks/sdata_train_pomegranate.csv', index=False)\n",
        "print(\"Synthetic Data (Training) saved to synthetic_data_train1.csv\")\n",
        "# Saving the model in the TensorFlow SavedModel format\n",
        "# generator.save('/content/drive/MyDrive/Colab Notebooks/sdata_generator_model.h5')"
      ],
      "metadata": {
        "id": "mAtWLDnpPWt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the min and max values for each feature in the original data\n",
        "original_mins = real_data.min()\n",
        "original_maxs = real_data.max()\n",
        "\n",
        "# Scale the synthetic data to the range observed in the original data\n",
        "for column in synthetic_df_train.columns:\n",
        "    if column != 'label':  # Skip the 'label' column\n",
        "        # Scale the column to the min and max values of the original data\n",
        "        synthetic_df_train[column] = synthetic_df_train[column] * (original_maxs[column] - original_mins[column]) + original_mins[column]\n",
        "\n",
        "# Set the 'label' column to 'rice'\n",
        "synthetic_df_train['label'] = 'pomegranate'\n",
        "\n",
        "# Save the scaled synthetic data to a CSV file\n",
        "synthetic_df_train.to_csv('/content/drive/MyDrive/Colab Notebooks/s_data_train_pomegranate.csv', index=False)\n",
        "print(\"Synthetic Data (Training) saved to synthetic_data_train.csv\")"
      ],
      "metadata": {
        "id": "4K6TJoFZsYNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/synthetic_data_train_apple.csv')"
      ],
      "metadata": {
        "id": "a-niwx7ct932"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "for column in real_data.columns:\n",
        "    if column != 'label':  # Assuming 'label' is a categorical column\n",
        "        plt.figure(figsize=(10, 4))\n",
        "        sns.histplot(real_data[column], color='blue', kde=True, label='Original')\n",
        "        sns.histplot(synthetic_df_train[column], color='orange', kde=True, label='Synthetic', alpha=0.7)\n",
        "        plt.title(f'Histogram for {column}')\n",
        "        plt.legend()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "XEPhxKskuIrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for column in real_data.columns:\n",
        "    if column != 'label':  # Assuming 'label' is a categorical column\n",
        "        plt.figure(figsize=(10, 4))\n",
        "        sns.histplot(real_data[column], color='green', kde=True, label='Original')\n",
        "        sns.histplot(synthetic_df_train[column], color='purple', kde=True, label='Synthetic', alpha=0.7)\n",
        "        plt.title(f'Histogram for {column}')\n",
        "        plt.legend()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "np1TzBDg3QZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming you have numeric columns in the 'rice' DataFrame\n",
        "\n",
        "s=s.corr()\n",
        "# Set up the matplotlib figure\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "# Create a heatmap using seaborn\n",
        "sns.heatmap(s, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "\n",
        "# Display the plot\n",
        "plt.title('Correlation Matrix - Rice Data')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nK-XNEvvOr38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# tgan_data=pd.read_csv(\"/content/TABGAN.csv\")"
      ],
      "metadata": {
        "id": "B5fjaT0tJVps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# correlation_matrix =tgan_data.corr()\n",
        "# correlation_coefficient = correlation_matrix.iloc[0, 1]"
      ],
      "metadata": {
        "id": "NMWPCIaUmC1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YSjRq7aY_5wD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}